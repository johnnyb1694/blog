<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.54.0" />


<title>Exploring the speeches and letters of Abraham Lincoln - Johnny&#39;s Blog</title>
<meta property="og:title" content="Exploring the speeches and letters of Abraham Lincoln - Johnny&#39;s Blog">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/yin-yang.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/">Posts</a></li>
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/johnnyb1694">GitHub</a></li>
    
    <li><a href="https://www.linkedin.com/in/johnnybreen/">LinkedIn</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">16 min read</span>
    

    <h1 class="article-title">Exploring the speeches and letters of Abraham Lincoln</h1>

    
    <span class="article-date">2019-04-22</span>
    

    <div class="article-content">
      


<div id="preamble-on-project-gutenberg" class="section level1">
<h1>Preamble on ‘Project Gutenberg’</h1>
<p>It’s been a little while since I’ve practiced text mining so I thought I would analyse some textual data provided by Project Gutenberg. In case you were not aware, Project Gutenberg consists of various articles and literary contributions (amongst other things) written, in the main, by authors whose works are now in the US public domain and largely exempt from any copyright infringement. For the UK, the law is that copyright applies to somebody else’s work until <a href="https://www.gov.uk/copyright/how-long-copyright-lasts">70 years after their date of death</a>.</p>
<p>Luckily for us, there is a package in R, <a href="https://cran.r-project.org/web/packages/gutenbergr/vignettes/intro.html">gutenbergr</a>, which allows you to easily download and access written articles stored within the Project Gutenberg database within the click of a button!</p>
</div>
<div id="background" class="section level1">
<h1>Background</h1>
<p>Upon inspecting the various repositories of data available to me in Project Gutenberg, I became rather fascinated by the prospect of analysing Abraham Lincoln’s various letters and writings composed between the years 1832 and 1865 (Lincoln’s year of death). I don’t particularly know much about Abraham Lincoln, I’m ashamed to say, but I wanted to see how much I could learn about the former president by simply performing a short text-mining exercise on the extensive repository of written letters he compiled over the course of his political career.</p>
<p>This is not an in-depth analysis of Lincoln’s writings; however, I was able to make some progress in answering the following questions:</p>
<ul>
<li>What are Lincoln’s commonly used terms?</li>
<li>Can we track Lincoln’s mental state of mind over the course of his political career? Does he tend to use more negative language at certain points in time? Does this line up with historical moments in his career?</li>
<li>Which themes became more important to Lincoln during the course of his political career? Which themes became less relevant?</li>
</ul>
<p>The latter two questions require a timestamp variable which must be engineered from the underlying data - more on this shortly!</p>
</div>
<div id="preliminaries" class="section level1">
<h1>Preliminaries</h1>
<p>First, we load the necessary packages for this short analysis - I’ve added a comment besides each package to explain how it is used within the remainder of this article:</p>
<pre class="r"><code>library(gutenbergr) # allows you to download articles stored within the Project Gutenberg database
library(tidyverse) # includes various data manipulation packages, most notably &#39;tidyr&#39; and &#39;dplyr&#39;
library(tidytext) # facilitates text mining
library(broom) # allows you to &#39;tidy&#39; model outputs into a tibble format
library(ggthemes) # purely for &#39;theme_solarized2()&#39; - see below!
library(ggrepel) # purely for plotting aesthetically viable text labels on a ggplot2 visualisation

theme_set(theme_solarized_2()) # sets a global theme for ggplot2 visualisations</code></pre>
</div>
<div id="data-import" class="section level1">
<h1>Data import</h1>
<p>The first step we must take is to download the articles he wrote using the <code>gutenbergr</code> package:</p>
<pre class="r"><code>lincoln_raw &lt;- gutenberg_download(2653:2659) # ids 2653 to 2659 encode Lincoln&#39;s writings between 1832 and 1865</code></pre>
</div>
<div id="data-cleansing" class="section level1">
<h1>Data cleansing</h1>
<p>First let’s tidy the data. There was an initial challenge I had with this data - you can observe that the date associated with each article is actually stored within the textual field. I’ll take a ‘slice’ of the data between two lines of data which I know contain a relevant date to demonstrate the issue (this slice appears to correspond to a letter from Roosevelt after Lincoln’s death):</p>
<pre class="r"><code>lincoln_raw %&gt;%
  slice(131:140)</code></pre>
<pre><code>## # A tibble: 10 x 2
##    gutenberg_id text                                                       
##           &lt;int&gt; &lt;chr&gt;                                                      
##  1         2653 puts in antithesis. Abraham Lincoln, the rail-splitter, th…
##  2         2653 country lawyer, was one of the shrewdest and most enlighte…
##  3         2653 world, and he had all the practical qualities which enable…
##  4         2653 guide his countrymen; and yet he was also a genius of the …
##  5         2653 a leader who rose level to the greatest crisis through whi…
##  6         2653 or any other nation had to pass in the nineteenth century. 
##  7         2653 &quot;&quot;                                                         
##  8         2653 THEODORE ROOSEVELT                                         
##  9         2653 &quot;&quot;                                                         
## 10         2653 SAGAMORE HILL, OYSTER BAY, N. Y., September 22, 1905.</code></pre>
<p>I wanted an extra variable to encode the year of each relevant writing. In order to achieve this, I’d have to use the <code>stringr</code> package from the <code>tidyverse</code>. My thought process was to:</p>
<ul>
<li>Assume that any text with 4 digits corresponded to a year (not unreasonable but there could be exceptions);</li>
<li>Extract said year if it was detected in the textual field, using a simple regular expression</li>
<li>Since it seems to be the case that every letter starts with a date, assume that this date represents every line that follows <em>until</em> reaching the next date</li>
</ul>
<p>I’m using the term ‘date’ very loosely here. What I am doing, in reality, is extracting the <em>year</em> (as opposed to the precise date) in which the letter was written and that is sufficient for the purpose of this exercise as we will see shortly. I also apply other pre-processing steps to the raw data, supplemented by comments below:</p>
<pre class="r"><code>lincoln_clean &lt;- lincoln_raw %&gt;%
  unnest_tokens(output = word, input = text) %&gt;%
  mutate(unique_id = row_number(), year = ifelse(str_detect(word, regex(&quot;\\d{4}&quot;)), word, NA_character_)) %&gt;%
  fill(year) %&gt;% # assume that the extracted year is constant for a given letter up until a new letter is written 
  mutate_at(vars(year), .funs = funs(as.integer)) %&gt;%
  filter(between(year, 1832, 1865), # these are the only dates at which it was possible for Lincoln to have written something 
         !str_detect(word, &quot;lincoln&quot;), # I don&#39;t want Lincoln&#39;s name to be included as a value
         str_detect(word, &quot;[a-z]&quot;)) %&gt;% # get rid of any numbers or digits - these aren&#39;t &#39;words&#39; I want to consider
  anti_join(stop_words) # get rid of words like &#39;to&#39;, &#39;the&#39; or &#39;and&#39; 

lincoln_clean</code></pre>
<pre><code>## # A tibble: 151,038 x 4
##    gutenberg_id word       unique_id  year
##           &lt;int&gt; &lt;chr&gt;          &lt;int&gt; &lt;int&gt;
##  1         2653 spoke             75  1864
##  2         2653 grave             83  1864
##  3         2653 question          84  1864
##  4         2653 government        87  1864
##  5         2653 strong            90  1864
##  6         2653 liberties         93  1864
##  7         2653 people            96  1864
##  8         2653 strong            99  1864
##  9         2653 maintain         102  1864
## 10         2653 existence        104  1864
## # … with 151,028 more rows</code></pre>
</div>
<div id="exploratory-data-analysis" class="section level1">
<h1>Exploratory data analysis</h1>
<div id="word-frequency-plot" class="section level2">
<h2>Word-Frequency Plot</h2>
<p>As is perhaps always the first step in any text mining exercise, let’s have a quick look at which words seem to appear most frequently in Lincoln’s writings:</p>
<pre class="r"><code>lincoln_clean %&gt;%
  count(word, sort = TRUE) %&gt;%
  top_n(20, n) %&gt;%
  mutate(word = fct_reorder(word, n)) %&gt;%
  ggplot(aes(x = word, y = n, colour = n)) +
  geom_point() +
  geom_segment(aes(x = word, xend = word, y = 0, yend = n)) +
  scale_colour_gradient(low = &quot;slateblue1&quot;, high = &quot;tomato1&quot;) +
  coord_flip() +
  labs(x = &quot;Word&quot;,
       y = &quot;Frequency&quot;,
       colour = &quot;Count&quot;,
       title = &quot;Top 20 most frequent terms in Lincoln&#39;s writings&quot;,
       subtitle = &quot;Key themes include slavery and war amongst others&quot;,
       caption = &quot;Source: &#39;Project Gutenberg&#39; archive&quot;)</code></pre>
<p><img src="/post/2019-04-22-exploring-the-speeches-and-letters-of-abraham-lincoln_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>You can see some clear themes emerging already such as slavery and war.</p>
</div>
<div id="sentiment-tracker-plot" class="section level2">
<h2>Sentiment tracker plot</h2>
<p>One cool thing we can do that is facilitated by the <code>tidytext</code> package is the ability to track individual ‘sentiments’ over time. By ‘sentiment’ we are referring to the ‘positivity’ or ‘negativity’ of emotion over time. This is enabled by the <code>tidytext::get_sentiments()</code> function and the correspoding <code>afinn</code> lexicon:</p>
<pre class="r"><code>term_scores &lt;- get_sentiments(lexicon = &quot;afinn&quot;)

term_scores </code></pre>
<pre><code>## # A tibble: 2,476 x 2
##    word       score
##    &lt;chr&gt;      &lt;int&gt;
##  1 abandon       -2
##  2 abandoned     -2
##  3 abandons      -2
##  4 abducted      -2
##  5 abduction     -2
##  6 abductions    -2
##  7 abhor         -3
##  8 abhorred      -3
##  9 abhorrent     -3
## 10 abhors        -3
## # … with 2,466 more rows</code></pre>
<p>The <code>afinn</code> lexicon ranks 2,476 relatively common words (mainly verbs and adjectives) with a score ranging from <code>-5</code> to <code>+5</code> based on how ‘negative’ or ‘positive’ the word is deemed to be, respectively. So, for instance, <code>abandon</code> is a relatively negative word (with a score of <code>-2</code>) but not as negative as something like <code>abhor</code> (with a score of <code>-3</code>) - I think we can come to a consensus on that.</p>
<p>The power of having access to this lexicon is that you can perform a join on this table with the existing one word per row per document format provided by <code>lincoln_clean</code> to get an associated with the rating of each word in Lincoln’s writings. You can either perform an <code>inner_join()</code> or a <code>left_join()</code> depending on whether you want to retain words without a match in the <code>afinn</code> lexicon. I went with the former:</p>
<pre class="r"><code>lincoln_clean %&gt;%
  inner_join(get_sentiments(&quot;afinn&quot;)) %&gt;%
  group_by(year) %&gt;%
  summarise(avg_sentiment = mean(score, na.rm = TRUE),
            year_count = n()) %&gt;%
  ggplot(aes(x = year, y = avg_sentiment)) +
  geom_point(aes(size = year_count, colour = avg_sentiment), show.legend = FALSE) +
  geom_line(alpha = 0.50, colour = &quot;black&quot;) +
  geom_label_repel(data = . %&gt;% filter(!between(avg_sentiment, -0.5, 0.5)),
                   mapping = aes(label = year),
                   size = 3) +
  scale_colour_gradient(low = &quot;tomato1&quot;, high = &quot;slateblue1&quot;) +
  scale_x_continuous(breaks = seq(1830, 1865, 5)) +
  expand_limits(y = c(-1, 1)) +
  labs(x = &quot;Year of study&quot;,
       y = &quot;Sentiment score&quot;,
       title = &quot;Progression of Lincoln&#39;s mental state over time&quot;,
       subtitle = &quot;The size of the points corresponds to the volume of data available as at that year&quot;,
       caption = &quot;Source: &#39;Project Gutenberg&#39; archive&quot;)</code></pre>
<p><img src="/post/2019-04-22-exploring-the-speeches-and-letters-of-abraham-lincoln_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Whilst this series appears to be relatively stationary, I’ve highlighted particularly strong periods of emotion with different colours (red is more negative). This is a good point to dig deeper into that period between 1840 and 1845 to figure out whether this supposed low-to-high jump is simply a result of insufficient data, especially during the years 1841 and 1843, or whether it is a reflection of a genuine emotional journey experienced by Lincoln during this period of time.</p>
<p>Indeed, a quick inspection of the year variable indicates that insufficient data might be the cause of the emotional spikes:</p>
<pre class="r"><code># an overall inspection of year-counts
lincoln_clean %&gt;%
  count(year, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 34 x 2
##     year     n
##    &lt;int&gt; &lt;int&gt;
##  1  1863 20797
##  2  1861 19688
##  3  1862 18650
##  4  1864 15767
##  5  1858 12988
##  6  1854  9859
##  7  1865  6007
##  8  1856  5347
##  9  1850  5062
## 10  1860  4033
## # … with 24 more rows</code></pre>
<pre class="r"><code># filtering on 1841 and 1843...
lincoln_clean %&gt;%
  count(year, sort = TRUE) %&gt;%
  filter(year %in% c(1841, 1843))</code></pre>
<pre><code>## # A tibble: 2 x 2
##    year     n
##   &lt;int&gt; &lt;int&gt;
## 1  1841  1665
## 2  1843  1493</code></pre>
<p>Still, with over 1,000 words in each year category there is perhaps some evidence that such writings may have reflected truly genuine emotional concerns on Lincoln’s part. I’m particularly curious about what on earth happened during 1841 and 1843:</p>
<pre class="r"><code>lincoln_text_4143 &lt;- lincoln_clean %&gt;%
  filter(year %in% c(1841, 1843)) %&gt;%
  nest(-year) %&gt;%
  mutate(text_composition = map_chr(data, ~ str_flatten(.$word, collapse = &quot; &quot;))) %&gt;%
  select(year, text_composition)

lincoln_text_4143[1,2, drop = TRUE] %&gt;% str_sub(start = 1L, end = 1000L)</code></pre>
<pre><code>## [1] &quot;john stuart depression springfield jan dear stuart miserable living feel equally distributed human family cheerful earth forbode remain impossible die appears fear unable attend business change scene remain home judge logan write remarks illinois legislature january house representatives january discussing continuation illinois michigan canal moore afraid holders scrip lose napier danger examined amount scrip principal mind obliged certificates altogether voluntary apprehend fall hands loss fall citizens section country scrip circulate extensive range country confined chiefly vicinity canal representatives section country favor bill propose protect leave care run risk reasonable suppose competent protect fair circular whig committee february appeal people illinois fellow citizens assembly adjourning assembled november bankrupt public treasury pecuniary embarrassments prevailing department society dilapidated public impending danger degradation expect representatives lose time devising &quot;</code></pre>
<pre class="r"><code>cat(&quot;\n&quot;)</code></pre>
<pre class="r"><code>lincoln_text_4143[2,2, drop = TRUE] %&gt;% str_sub(start = 1L, end = 1000L)</code></pre>
<pre><code>## [1] &quot;resolutions whig meeting springfield illinois march object meeting stated springfield offered resolutions unanimously adopted resolved tariff duties imported producing sufficient revenue payment expenditures national government adjusted protect american industry indispensably prosperity american people resolved opposed direct taxation support national government resolved national bank properly restricted highly proper establishment maintenance sound currency cheap safe collection keeping disbursing public revenue resolved distribution proceeds sales public lands principles clay&#39;s bill accords nation illinois resolved recommend whigs congressional district nominate support approaching election candidate principles chances success resolved recommend whigs portions adopt rigidly adhere convention system nominating candidates resolved recommend whigs congressional district hold district convention monday composed delegates county equal double representatives assembly provided county delega&quot;</code></pre>
<p>The printouts above show the words which make up the first 1,000 characters of writings in 1841 and 1843 respectively. It’s clear to see that the former could be considered to be much more ‘negative’ in its word composition than the latter. Lincoln is clearly discussing being ‘miserable’ and suffering from possible ‘depression’ - we see words like ‘risk’, ‘fall’ and ‘loss’ too. By contrast, the second writing is completely different - this is a writing about the adoption of an agreed political policy with seeming ‘success’.</p>
<p>I did a little more digging online about the letters Lincoln wrote during 1841 and came across the following letter to John Stuart (a prominent lawyer in the USA at the time), the content of which appears to match the printout above:</p>
<blockquote>
<p>For not giving you a general summary of news, you must pardon me; it is not in my power to do so. I am now the most miserable man living. If what I feel were equally distributed to the whole human family, there would not be one cheerful face on earth. Whether I shall ever be better, I cannot tell; I awfully forebode I shall not. To remain as I am is impossible; I must die or be better, it appears to me. The matter you speak of on my account you may attend to as you say, unless you shall hear of my condition forbidding it. I say this because I fear I shall be unable to attend to any business here, and a change of scene might help me. If I could be myself, I would rather remain at home with Judge Logan. I can write no more.</p>
</blockquote>
<p>According to <a href="http://housedivided.dickinson.edu/sites/lincoln/letter-to-john-stuart-january-23-1841/">this source</a>, the cause of Lincoln’s depression at the time “resulted entirely from the situation he . . . got himself into – he was engaged to Miss Todd, and in love with Miss Edwards, and his conscience troubled him dreadfully for the supposed injustice he had done, and the supposed violation of his word which he had committed”.</p>
</div>
<div id="growing-and-shrinking-themes" class="section level2">
<h2>Growing and shrinking themes</h2>
<p>The other exploratory analysis we wanted to track was whether there were any words used by Lincoln which became more prominent or less prominent over time.</p>
<p>To achieve this we fit a logistic regression model to each ‘word’ in the data where the y-variable is the incidence of a word in a given year and the x-variable is the year of study. In other words, for each word we have how many times that specific word was used in a certain year in relation to how many times <em>any</em> word was used in a certain year - i.e. we have the number of ‘successes’ and the number of ‘trials’ for each word and for each year.</p>
<p>First, we need to make sure that we don’t include words which grow significantly over only two years but have no usage elsewhere - we want words that have been used fairly regulalry over the course of the 33 years of study. I will choose more than 20 appearances:</p>
<pre class="r"><code>lincoln_reg_used_words &lt;- lincoln_clean %&gt;%
  distinct(word, year) %&gt;%
  group_by(word) %&gt;%
  summarise(total_appearances = n()) %&gt;%
  filter(total_appearances &gt; 20) %&gt;% 
  pull(word) # words with at least 20 years of data

# have a quick inspection of what types of words are used regularly
set.seed(123)
lincoln_reg_used_words %&gt;% sample(5)</code></pre>
<pre><code>## [1] &quot;force&quot;      &quot;set&quot;        &quot;january&quot;    &quot;ten&quot;        &quot;understand&quot;</code></pre>
<pre class="r"><code>lincoln_reg_used_words %&gt;% sample(5)</code></pre>
<pre><code>## [1] &quot;brought&quot;  &quot;missouri&quot; &quot;time&quot;     &quot;nation&quot;   &quot;late&quot;</code></pre>
<p>We only need the year and word variables to fit a logistic regression to each word:</p>
<pre class="r"><code>year_counts &lt;- lincoln_clean %&gt;%
  count(year)

lincoln_counts &lt;- lincoln_clean %&gt;%
  select(year, word) %&gt;%
  filter(word %in% lincoln_reg_used_words) %&gt;%
  add_count(year, word) %&gt;%
  inner_join(year_counts, by = c(&quot;year&quot; = &quot;year&quot;)) %&gt;%
  group_by(year, word) %&gt;%
  summarise(successes = sum(n.x), trials = sum(n.y)) %&gt;%
  ungroup() %&gt;%
  mutate(prop_success = successes / trials) %&gt;%
  filter(trials &gt; 1000) # for statistical significance

lincoln_slopes &lt;- lincoln_counts %&gt;%
  nest(-word) %&gt;%
  mutate(log_mod = map(data, ~ glm(cbind(successes, trials - successes) ~ year, family = &quot;binomial&quot;, data = .))) %&gt;%
  unnest(map(log_mod, broom::tidy)) %&gt;%
  filter(term == &quot;year&quot;) %&gt;%
  arrange(desc(estimate))

lincoln_slopes</code></pre>
<pre><code>## # A tibble: 177 x 6
##    word       term  estimate std.error statistic   p.value
##    &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1 january    year    0.385    0.0125      30.8  1.16e-208
##  2 washington year    0.150    0.00181     82.9  0.       
##  3 march      year    0.131    0.00951     13.8  3.31e- 43
##  4 war        year    0.0905   0.00182     49.8  0.       
##  5 june       year    0.0834   0.00717     11.6  2.81e- 31
##  6 received   year    0.0544   0.00348     15.6  4.88e- 55
##  7 day        year    0.0506   0.00216     23.4  9.66e-121
##  8 force      year    0.0504   0.00387     13.0  1.04e- 38
##  9 election   year    0.0468   0.00330     14.2  1.44e- 45
## 10 morning    year    0.0445   0.00901      4.94 7.75e-  7
## # … with 167 more rows</code></pre>
<p>Now that we have fit a logistic model to each word we can extract trends in Lincoln’s writings which emerged over time (the highest growing trends) and, equally, trends which appeared to regress over time. We can do this because the ‘estimate’ field in the table printed above reflects how correlated each word is with year of usage. For instance, ‘january’ has a coefficient estimate of <code>0.3853...</code> which implies an increase of one year corresponds to a <code>exp(0.38) = 46%</code> increase in the usage of ‘january’:</p>
<pre class="r"><code>lincoln_top_growing &lt;- lincoln_slopes %&gt;%
  top_n(10, estimate) %&gt;%
  pull(word)

lincoln_top_shrinking &lt;- lincoln_slopes %&gt;%
  top_n(-10, estimate) %&gt;%
  pull(word)</code></pre>
<p>Let us now plot the growth or regression of each of these sets of words in a time series plot:</p>
<pre class="r"><code># words which Lincoln began to use more towards the end of his writings
lincoln_counts %&gt;%
  filter(word %in% lincoln_top_growing) %&gt;%
  ggplot(aes(x = year, y = prop_success, colour = word)) +
  geom_line(show.legend = FALSE) +
  facet_wrap(~word) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = &quot;Year&quot;,
       y = &quot;Usage proportion&quot;,
       title = &quot;Top 10 highest growing words&quot;,
       subtitle = &quot;&#39;war&#39; and &#39;washington&#39; make noticeable appearances&quot;,
       caption = &quot;Source: &#39;Project Gutenberg&#39; archive&quot;)</code></pre>
<p><img src="/post/2019-04-22-exploring-the-speeches-and-letters-of-abraham-lincoln_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre class="r"><code># words which Lincoln started to use less frequently towards the end of his writings
lincoln_counts %&gt;%
  filter(word %in% lincoln_top_shrinking) %&gt;%
  ggplot(aes(x = year, y = prop_success, colour = word)) +
  geom_line(show.legend = FALSE) +
  facet_wrap(~word) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = &quot;Year&quot;,
     y = &quot;Usage proportion&quot;,
     title = &quot;Top 10 highest shrinking words&quot;,
     subtitle = &quot;Themes of liberty, such as &#39;free&#39; and &#39;slavery&#39;, appear to decrease in usage over time&quot;,
     caption = &quot;Source: &#39;Project Gutenberg&#39; archive&quot;)</code></pre>
<p><img src="/post/2019-04-22-exploring-the-speeches-and-letters-of-abraham-lincoln_files/figure-html/unnamed-chunk-14-2.png" width="672" /></p>
<p>After a little bit of research, it doesn’t surprise me that ‘slavery’ became much less prominent post 1860. One hypothesis I have (perhaps naively) is that the American Civil War broke out in 1861, by which point Lincoln had exhausted his thoughts on slavery and now found himself in a brutal war over the issue. The breakout of the war also goes some way to explain why words like ‘war’ and ‘washington’ shot up in prominence post 1860 - this might also explain the word ‘received’ as a potential correlator with war.</p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>We have only engaged in a brief, but nonetheless useful, analysis of Lincoln’s written correspondence. There are many other routes I could have followed with this analysis, but ultimately decided not to in the interest of time. For instance, I could have inspected the difference between each of Lincoln’s volume of writings in more detail through a tf-idf analysis or otherwise. I could have inspected words with a strong correlaton or cosine similarity. These are techniques which are explored in many text mining articles online but I haven’t explored them in this post.</p>
<p>I’m currently researching <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation (LDA)</a> which is a type of topic model used in text mining. Broadly speaking it assembles textual data into different categories through Bayesian inference. I plan to include a series of posts very soon explaining some of the key parts of this algorithm - stay tuned!</p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

